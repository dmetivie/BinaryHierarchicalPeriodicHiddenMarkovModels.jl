function Œ≥‚Çõ!(Œ≥‚Çõ, Œ≥, n_all)
    K, D, size_memory, T, rain_cat = size(Œ≥‚Çõ)
    for tup in Iterators.product(1:D, 1:size_memory, 1:T, 1:rain_cat)
        for k = 1:K
            Œ≥‚Çõ[k, tup...] = sum(Œ≥[n, k] for n in n_all[tup...]; init = 0)
        end
    end
end

function s_Œæ!(s_Œæ, Œæ, n_in_t)
    T, K = size(s_Œæ)
    for t = 1:T
        for (k, l) in Iterators.product(1:K, 1:K)
            s_Œæ[t, k, l] = sum(Œæ[n, k, l] for n in n_in_t[t])
        end
    end
    # * We add Œæ[N, k, l] but it should be zeros
end

function model_for_B(Œ≥‚Çõ::AbstractMatrix, d::Int; silence = true, max_cpu_time = 60.0, max_iter = 100)

    T, rain_cat = size(Œ≥‚Çõ)
    model = Model(Ipopt.Optimizer)
    set_optimizer_attribute(model, "max_cpu_time", max_cpu_time)
    set_optimizer_attribute(model, "max_iter", max_iter)

    silence && set_silent(model)
    f = 2œÄ / T
    cos_nj = [cos(f * j * t) for t = 1:T, j = 1:d]
    sin_nj = [sin(f * j * t) for t = 1:T, j = 1:d]
    trig = [[1; interleave2(cos_nj[t, :], sin_nj[t, :])] for t = 1:T]

    @variable(model, Œ∏_jump[j = 1:(2d+1)])
    # Polynomial P
    @NLexpression(model, P‚Çô[t = 1:T], sum(trig[t][j] * Œ∏_jump[j] for j = 1:length(trig[t])))

    @NLparameter(model, œÄ‚Çõ[t = 1:T, y = 1:rain_cat] == Œ≥‚Çõ[t, y])
    œÄ‚Çõ
    @NLexpression(model, mle,
        -sum(œÄ‚Çõ[t, 1] * log1p(exp(-P‚Çô[t])) for t = 1:T) - sum(œÄ‚Çõ[t, 2] * log1p(exp(+P‚Çô[t])) for t = 1:T)
    ) # 1 is where it did not rain # 2 where it rained
    @NLobjective(
        model, Max,
        mle
    )
    # I don't know if it is the best but https://discourse.julialang.org/t/jump-updating-nlparameter-of-a-model-in-a-loop/35081/3
    model[:œÄ‚Çõ] = œÄ‚Çõ
    return model
end

function update_B!(B::AbstractArray{T,4} where {T}, Œ∏·¥Æ::AbstractArray{N,4} where {N}, Œ≥::AbstractMatrix, Œ≥‚Çõ::AbstractArray, ùêò, n_all, model_B::Model; warm_start = true)
    @argcheck size(Œ≥, 1) == size(ùêò, 1)
    @argcheck size(Œ≥, 2) == size(B, 1)
    N = size(Œ≥, 1)
    K = size(B, 1)
    T = size(B, 2)
    D = size(B, 3)
    size_memory = size(B, 4)
    ## For periodicHMM only the n ùêò corresponding to B(t) are used to update B(t)
    ## Update the smoothing parameters in the JuMP model

    Œ≥‚Çõ!(Œ≥‚Çõ, Œ≥, n_all) # update coefficient in JuMP model

    all_iter = Iterators.product(1:K, 1:D, 1:size_memory)
    #! TODO pmap option
    Œ∏_res = map(tup -> fit_mle_one_B(Œ∏·¥Æ[tup..., :], model_B, Œ≥‚Çõ[tup..., :, :]; warm_start=warm_start), all_iter)

    for (k, s, h) in all_iter
        Œ∏·¥Æ[k, s, h, :] = Œ∏_res[k, s, h]
    end

    p = [1 / (1 + exp(polynomial_trigo(t, Œ∏·¥Æ[k, s, h, :], T = T))) for k = 1:K, t = 1:T, s = 1:D, h = 1:size_memory]
    B[:, :, :, :] = Bernoulli.(p)
end

function fit_mle_one_B(Œ∏·¥Æ, model_B, Œ≥‚Çõ; warm_start = true)
    T, rain_cat = size(Œ≥‚Çõ)
    Œ∏_jump = model_B[:Œ∏_jump]
    warm_start && set_start_value.(Œ∏_jump, Œ∏·¥Æ[:])
    œÄ‚Çõ = model_B[:œÄ‚Çõ]

    for t = 1:T, y = 1:rain_cat
        set_value(œÄ‚Çõ[t, y], Œ≥‚Çõ[t, y])
    end
    optimize!(model_B)
    return value.(Œ∏_jump)
end

# JuMP model use to increase R(Œ∏,Œ∏^i) for the Q(t) matrix
function model_for_A(s_Œæ::AbstractArray, d::Int; silence = true)
    T, K = size(s_Œæ)
    model = Model(Ipopt.Optimizer)
    set_optimizer_attribute(model, "max_iter", 200)
    silence && set_silent(model)
    f = 2œÄ / T
    cos_nj = [cos(f * j * t) for t = 1:T, j = 1:d]
    sin_nj = [sin(f * j * t) for t = 1:T, j = 1:d]

    trig = [[1; interleave2(cos_nj[t, :], sin_nj[t, :])] for t = 1:T]

    @variable(model, pklj_jump[l = 1:(K-1), j = 1:(2d+1)], start = 0.01)
    # Polynomial P_kl
    @NLexpression(model, Pkl[t = 1:T, l = 1:K-1], sum(trig[t][j] * pklj_jump[l, j] for j = 1:length(trig[t])))

    @NLparameter(model, s_œÄkl[t = 1:T, l = 1:K-1] == s_Œæ[t, l])
    #TODO? is it useful to define the extra parameter for the sum?
    @NLparameter(model, s_œÄk[t = 1:T] == sum(s_Œæ[t, l] for l = 1:K))

    @NLobjective(
        model,
        Max,
        sum(sum(s_œÄkl[t, l] * Pkl[t, l] for l = 1:K-1) - s_œÄk[t] * log1p(sum(exp(Pkl[t, l]) for l = 1:K-1)) for t = 1:T)
    )
    # To add NL parameters to the model for later use https://discourse.julialang.org/t/jump-updating-nlparameter-of-a-model-in-a-loop/35081/3
    model[:s_œÄkl] = s_œÄkl
    model[:s_œÄk] = s_œÄk
    return model
end

function update_A!(
    A::AbstractArray{<:AbstractFloat,3},
    Œ∏·¥¨::AbstractArray{<:AbstractFloat,3},
    Œæ::AbstractArray,
    s_Œæ::AbstractArray,
    Œ±::AbstractMatrix,
    Œ≤::AbstractMatrix,
    LL::AbstractMatrix,
    n2t::AbstractArray{Int},
    n_in_t,
    model_A::Model;
    warm_start = true
) 
    @argcheck size(Œ±, 1) == size(Œ≤, 1) == size(LL, 1) == size(Œæ, 1)
    @argcheck size(Œ±, 2) ==
              size(Œ≤, 2) ==
              size(LL, 2) ==
              size(A, 1) ==
              size(A, 2) ==
              size(Œæ, 2) ==
              size(Œæ, 3)

    N, K = size(LL)
    T = size(A, 3)
    @inbounds for n in OneTo(N - 1)
        t = n2t[n] # periodic t
        m = vec_maximum(view(LL, n + 1, :))
        c = 0

        for i in OneTo(K), j in OneTo(K)
            Œæ[n, i, j] = Œ±[n, i] * A[i, j, t] * exp(LL[n+1, j] - m) * Œ≤[n+1, j]
            c += Œæ[n, i, j]
        end

        for i in OneTo(K), j in OneTo(K)
            Œæ[n, i, j] /= c
        end
    end
    ## 
    # Œæ are the filtering probablies
    s_Œæ!(s_Œæ, Œæ, n_in_t)
    #! TODO pmap option
    Œ∏_res = map(k -> fit_mle_one_A(Œ∏·¥¨[k, :, :], model_A, s_Œæ[:, k, :]; warm_start = warm_start), 1:K)

    for k = 1:K
        Œ∏·¥¨[k, :, :] = Œ∏_res[k][:, :]
    end

    for k = 1:K, l = 1:K-1, t = 1:T
        A[k, l, t] = exp(polynomial_trigo(t, Œ∏·¥¨[k, l, :], T=T))
    end
    for k = 1:K, t = 1:T
        A[k, K, t] = 1  # last colum is 1/normalization (one could do otherwise)
    end
    normalization_polynomial = [1 + sum(A[k, l, t] for l = 1:K-1) for k = 1:K, t = 1:T]
    for k = 1:K, l = 1:K, t = 1:T
        A[k, l, t] /= normalization_polynomial[k, t]
    end
end

function fit_mle_one_A(Œ∏·¥¨, model, s_Œæ; warm_start = true)
    T, K = size(s_Œæ)
    pklj_jump = model[:pklj_jump]
    s_œÄk = model[:s_œÄk]
    s_œÄkl = model[:s_œÄkl]
    ## Update the smoothing parameters in the JuMP model
    for t = 1:T
        set_value(s_œÄk[t], sum(s_Œæ[t, l] for l = 1:K))
        for l = 1:K-1
            set_value(s_œÄkl[t, l], s_Œæ[t, l])
        end
    end
    warm_start && set_start_value.(pklj_jump, Œ∏·¥¨[:, :])
    # Optimize the updated model
    optimize!(model)
    # Obtained the new parameters
    return value.(pklj_jump)
end

function fit_mle!(
    hmm::HierarchicalPeriodicHMM,
    Œ∏·¥¨::AbstractArray{<:AbstractFloat,3},
    Œ∏·¥Æ::AbstractArray{<:AbstractFloat,4},
    ùêò::AbstractArray{<:Bool},
    ùêò_past::AbstractArray{<:Bool}
    ;
    n2t=n_to_t(size(ùêò, 1), size(hmm, 3))::AbstractVector{<:Integer},
    display=:none,
    maxiter=100,
    tol=1e-3,
    robust=false,
    silence=true,
    warm_start=true
)
    @argcheck display in [:none, :iter, :final]
    @argcheck maxiter >= 0

    N, K, T, size_memory, D = size(ùêò, 1), size(hmm, 1), size(hmm, 3), size(hmm, 4), size(hmm, 2)

    deg_Œ∏·¥¨ = (size(Œ∏·¥¨, 3) - 1) √∑ 2
    deg_Œ∏·¥Æ = (size(Œ∏·¥Æ, 4) - 1) √∑ 2
    rain_cat = 2 # dry or wet
    @argcheck T == size(hmm.B, 2)
    history = EMHistory(false, 0, [])

    all_Œ∏·¥¨·µ¢ = [copy(Œ∏·¥¨)]
    all_Œ∏·¥Æ·µ¢ = [copy(Œ∏·¥Æ)]
    # Allocate memory for in-place updates
    c = zeros(N)
    Œ± = zeros(N, K)
    Œ≤ = zeros(N, K)
    Œ≥ = zeros(N, K) # regular smoothing proba
    Œ≥‚Çõ = zeros(K, D, size_memory, T, rain_cat) # summed smoothing proba
    Œæ = zeros(N, K, K)
    s_Œæ = zeros(T, K, K)
    LL = zeros(N, K)

    # assign category for observation depending in the ùêò_past ùêò
    memory = Int(log2(size_memory))
    lag_cat = conditional_to(ùêò, ùêò_past)

    n_in_t = [findall(n2t .== t) for t = 1:T]
    n_occurence_history = [findall(.&(ùêò[:, j] .== y, lag_cat[:, j] .== h)) for j = 1:D, h = 1:size_memory, y = 0:1] # dry or wet
    n_all = [n_per_category(tup..., n_in_t, n_occurence_history) for tup in Iterators.product(1:D, 1:size_memory, 1:T, 1:rain_cat)]

    model_A = model_for_A(s_Œæ[:, 1, :], deg_Œ∏·¥¨, silence=silence) # JuMP Model for transition matrix
    model_B = model_for_B(Œ≥‚Çõ[1, 1, 1, :, :], deg_Œ∏·¥Æ, silence=silence) # JuMP Model for Emmission distribution

    loglikelihoods!(LL, hmm, ùêò, lag_cat; n2t=n2t)
    robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))

    forwardlog!(Œ±, c, hmm.a, hmm.A, LL; n2t=n2t)
    backwardlog!(Œ≤, c, hmm.a, hmm.A, LL; n2t=n2t)
    posteriors!(Œ≥, Œ±, Œ≤)

    logtot = sum(c)
    (display == :iter) && println("Iteration 0: logtot = $logtot")

    for it = 1:maxiter
        update_a!(hmm.a, Œ±, Œ≤)
        update_A!(hmm.A, Œ∏·¥¨, Œæ, s_Œæ, Œ±, Œ≤, LL, n2t, n_in_t, model_A; warm_start=warm_start)
        update_B!(hmm.B, Œ∏·¥Æ, Œ≥, Œ≥‚Çõ, ùêò, n_all, model_B; warm_start=warm_start)
        # Ensure the "connected-ness" of the states,
        # this prevents case where there is no transitions
        # between two extremely likely ùêò.
        robust && (hmm.A .+= eps())
    
        @check isprobvec(hmm.a)
        @check all(t -> istransmat(hmm.A[:, :, t]), OneTo(T))
    
        push!(all_Œ∏·¥¨·µ¢, copy(Œ∏·¥¨))
        push!(all_Œ∏·¥Æ·µ¢, copy(Œ∏·¥Æ))
    
        # loglikelihoods!(LL, hmm, ùêò, n2t)
        loglikelihoods!(LL, hmm, ùêò, lag_cat; n2t=n2t)
    
        robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))
    
        forwardlog!(Œ±, c, hmm.a, hmm.A, LL; n2t=n2t)
        backwardlog!(Œ≤, c, hmm.a, hmm.A, LL; n2t=n2t)
        posteriors!(Œ≥, Œ±, Œ≤)
    
        logtotp = sum(c)

        if display == :iter
            ŒîmaxA = round(maximum(abs, all_Œ∏·¥¨·µ¢[it+1] - all_Œ∏·¥¨·µ¢[it]), digits=5)
            ŒîmaxB = round(maximum(abs, all_Œ∏·¥Æ·µ¢[it+1] - all_Œ∏·¥Æ·µ¢[it]), digits=5)
            println("Iteration $it: logtot = $(round(logtotp, digits = 6)), max(|Œ∏·¥¨·µ¢-Œ∏·¥¨·µ¢‚Çã‚ÇÅ|) = ", ŒîmaxA, " & max(|Œ∏·¥Æ·µ¢-Œ∏·¥Æ·µ¢‚Çã‚ÇÅ|) = ", ŒîmaxB)
            # flush(stdout)
        end
    
        push!(history.logtots, logtotp)
        history.iterations += 1
    
        if abs(logtotp - logtot) < tol
            (display in [:iter, :final]) &&
                println("EM converged in $it iterations, logtot = $logtotp")
            history.converged = true
            break
        end
    
        logtot = logtotp
    end

    if !history.converged
        if display in [:iter, :final]
            println("EM has not converged after $(history.iterations) iterations, logtot = $logtot")
        end
    end

    history, all_Œ∏·¥¨·µ¢, all_Œ∏·¥Æ·µ¢
end

function fit_mle(hmm::HierarchicalPeriodicHMM,
    Œ∏·¥¨::AbstractArray{<:AbstractFloat,3},
    Œ∏·¥Æ::AbstractArray{<:AbstractFloat,4},
    ùêò::AbstractArray{<:Bool},
    ùêò_past::AbstractArray{<:Bool}; 
    Œ∏_iters=false, kwargs...)

    hmm = copy(hmm)
    Œ∏·¥¨ = copy(Œ∏·¥¨)
    Œ∏·¥Æ = copy(Œ∏·¥Æ)
    history, all_Œ∏·¥¨·µ¢, all_Œ∏·¥Æ·µ¢ = fit_mle!(hmm, Œ∏·¥¨, Œ∏·¥Æ, ùêò, ùêò_past; kwargs...)
    if Œ∏_iters == true
        return hmm, Œ∏·¥¨, Œ∏·¥Æ, history, all_Œ∏·¥¨·µ¢, all_Œ∏·¥Æ·µ¢
    else
        return hmm, Œ∏·¥¨, Œ∏·¥Æ, history
    end
end

# TODO add possibility of memory different at each site
# function fit_mle!(
#     hmm::HierarchicalPeriodicHMM,
#     ùêò::AbstractArray,
#     n2t::AbstractArray{Int},
#     Œ∏·¥¨::AbstractArray{TQ,3} where {TQ},
#     Œ∏·¥Æ::AbstractArray{TY,4} where {TY},
#     size_memories::AbstractVector # Vector of all local memory when there are not indentical
#     ;
#     display = :none,
#     maxiter = 100,
#     tol = 1e-3,
#     robust = false,
#     silence = true,
#     warm_start = true,
#     ùêò_past = [0 1 0 1 1 0 1 0 0 0
#         1 1 0 1 1 1 1 1 1 1
#         1 1 0 1 1 1 0 1 1 1
#         1 1 0 1 1 0 0 0 1 0
#         1 1 0 1 1 0 0 1 0 1]
# )
#     @argcheck display in [:none, :iter, :final]
#     @argcheck maxiter >= 0

#     N, K, T, D = size(ùêò, 1), size(hmm, 1), size(hmm, 3), size(hmm, 2)
#     @argcheck length(size_memories) == D
#     max_size_memory = maximum(size_memories)

#     deg_Œ∏·¥¨ = (size(Œ∏·¥¨, 3) - 1) √∑ 2
#     deg_Œ∏·¥Æ = (size(Œ∏·¥Æ, 4) - 1) √∑ 2
#     rain_cat = 2
#     @argcheck T == size(hmm.B, 2)
#     history = EMHistory(false, 0, [])

#     all_Œ∏·¥¨·µ¢ = [copy(Œ∏·¥¨)]
#     all_Œ∏·¥Æ·µ¢ = [copy(Œ∏·¥Æ)]
#     # Allocate memory for in-place updates
#     c = zeros(N)
#     Œ± = zeros(N, K)
#     Œ≤ = zeros(N, K)
#     Œ≥ = zeros(N, K) # regular smoothing proba
#     Œ≥‚Çõ = zeros(K, D, max_size_memory, T, rain_cat) # summed smoothing proba
#     Œæ = zeros(N, K, K)
#     s_Œæ = zeros(T, K, K)
#     LL = zeros(N, K)

#     # assign category for observation depending in the ùêò_past ùêò
#     memories = Int.(log.(size_memories) / log(2))
#     lag_cat = conditional_to(ùêò, ùêò_past)

#     n_in_t = [findall(n2t .== t) for t = 1:T]
#     n_occurence_history = [findall(.&(ùêò[:, j] .== y, lag_cat[:, j] .== h)) for j = 1:D, h = 1:max_size_memory, y = 0:1]
#     n_all = [n_per_category(tup..., n_in_t, n_occurence_history) for tup in Iterators.product(1:D, 1:max_size_memory, 1:T, 1:rain_cat)]

#     model_A = model_for_A(s_Œæ[:, 1, :], deg_Œ∏·¥¨, silence = silence) # JuMP Model for transition matrix
#     model_B = model_for_B(Œ≥‚Çõ[1, 1, 1, :, :], deg_Œ∏·¥Æ, silence = silence) # JuMP Model for Emmission distribution

#     loglikelihoods!(LL, hmm, ùêò, n2t, lag_cat)
#     robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))

#     forwardlog!(Œ±, c, hmm.a, hmm.A, LL, n2t)
#     backwardlog!(Œ≤, c, hmm.a, hmm.A, LL, n2t)
#     posteriors!(Œ≥, Œ±, Œ≤)

#     logtot = sum(c)
#     (display == :iter) && println("Iteration 0: logtot = $logtot")

#     for it = 1:maxiter
#         update_a!(hmm.a, Œ±, Œ≤)
#         update_A!(hmm.A, Œ∏·¥¨, Œæ, s_Œæ, Œ±, Œ≤, LL, n2t, n_in_t, model_A; warm_start = warm_start)
#         update_B!(hmm.B, Œ∏·¥Æ, Œ≥, Œ≥‚Çõ, ùêò, n_all, model_B; warm_start = warm_start)
#         # Ensure the "connected-ness" of the states,
#         # this prevents case where there is no transitions
#         # between two extremely likely ùêò.
#         robust && (hmm.A .+= eps())

#         @check isprobvec(hmm.a)
#         @check istransmats(hmm.A)

#         push!(all_Œ∏·¥¨·µ¢, copy(Œ∏·¥¨))
#         push!(all_Œ∏·¥Æ·µ¢, copy(Œ∏·¥Æ))

#         # loglikelihoods!(LL, hmm, ùêò, n2t)
#         loglikelihoods!(LL, hmm, ùêò, n2t, lag_cat)

#         robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))

#         forwardlog!(Œ±, c, hmm.a, hmm.A, LL, n2t)
#         backwardlog!(Œ≤, c, hmm.a, hmm.A, LL, n2t)
#         posteriors!(Œ≥, Œ±, Œ≤)

#         logtotp = sum(c)
#         (display == :iter) && println("Iteration $it: logtot = $logtotp")
#         flush(stdout)

#         push!(history.logtots, logtotp)
#         history.iterations += 1

#         if abs(logtotp - logtot) < tol
#             (display in [:iter, :final]) &&
#                 println("EM converged in $it iterations, logtot = $logtotp")
#             history.converged = true
#             break
#         end

#         logtot = logtotp
#     end

#     if !history.converged
#         if display in [:iter, :final]
#             println("EM has not converged after $(history.iterations) iterations, logtot = $logtot")
#         end
#     end

#     history, all_Œ∏·¥¨·µ¢, all_Œ∏·¥Æ·µ¢
# end