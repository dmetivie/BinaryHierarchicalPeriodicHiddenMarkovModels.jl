function Î³â‚›!(Î³â‚›, Î³, n_all)
    K, D, size_memory, T, rain_cat = size(Î³â‚›)
    for tup in Iterators.product(1:D, 1:size_memory, 1:T, 1:rain_cat)
        for k = 1:K
            Î³â‚›[k, tup...] = sum(Î³[n, k] for n in n_all[tup...]; init = 0)
        end
    end
end

function s_Î¾!(s_Î¾, Î¾, n_in_t)
    T, K = size(s_Î¾)
    for t = 1:T
        for (k, l) in Iterators.product(1:K, 1:K)
            s_Î¾[t, k, l] = sum(Î¾[n, k, l] for n in n_in_t[t])
        end
    end
    # * We add Î¾[N, k, l] but it should be zeros
end

function model_for_B(Î³â‚›::AbstractMatrix, d::Int; silence = true, max_cpu_time = 60.0, max_iter = 100)

    T, rain_cat = size(Î³â‚›)
    model = Model(Ipopt.Optimizer)
    set_optimizer_attribute(model, "max_cpu_time", max_cpu_time)
    set_optimizer_attribute(model, "max_iter", max_iter)

    silence && set_silent(model)
    f = 2Ï€ / T
    cos_nj = [cos(f * j * t) for t = 1:T, j = 1:d]
    sin_nj = [sin(f * j * t) for t = 1:T, j = 1:d]
    trig = [[1; interleave2(cos_nj[t, :], sin_nj[t, :])] for t = 1:T]

    @variable(model, Î¸_jump[j = 1:(2d+1)])
    # Polynomial P
    @NLexpression(model, Pâ‚™[t = 1:T], sum(trig[t][j] * Î¸_jump[j] for j = 1:length(trig[t])))

    @NLparameter(model, Ï€â‚›[t = 1:T, y = 1:rain_cat] == Î³â‚›[t, y])
    Ï€â‚›
    @NLexpression(model, mle,
        -sum(Ï€â‚›[t, 1] * log1p(exp(-Pâ‚™[t])) for t = 1:T) - sum(Ï€â‚›[t, 2] * log1p(exp(+Pâ‚™[t])) for t = 1:T)
    ) # 1 is where it did not rain # 2 where it rained
    @NLobjective(
        model, Max,
        mle
    )
    # I don't know if it is the best but https://discourse.julialang.org/t/jump-updating-nlparameter-of-a-model-in-a-loop/35081/3
    model[:Ï€â‚›] = Ï€â‚›
    return model
end

function update_B!(B::AbstractArray{T,4} where {T}, Î¸á´®::AbstractArray{N,4} where {N}, Î³::AbstractMatrix, Î³â‚›::AbstractArray, ð˜, n_all, model_B::Model; warm_start = true)
    @argcheck size(Î³, 1) == size(ð˜, 1)
    @argcheck size(Î³, 2) == size(B, 1)
    N = size(Î³, 1)
    K = size(B, 1)
    T = size(B, 2)
    D = size(B, 3)
    size_memory = size(B, 4)
    ## For periodicHMM only the n ð˜ corresponding to B(t) are used to update B(t)
    ## Update the smoothing parameters in the JuMP model

    Î³â‚›!(Î³â‚›, Î³, n_all) # update coefficient in JuMP model

    all_iter = Iterators.product(1:K, 1:D, 1:size_memory)

    Î¸_res = pmap(tup -> fit_mle_one_B(Î¸á´®[tup..., :], model_B, Î³â‚›[tup..., :, :]; warm_start=warm_start), all_iter)

    for (k, s, h) in all_iter
        Î¸á´®[k, s, h, :] = Î¸_res[k, s, h]
    end

    p = [1 / (1 + exp(polynomial_trigo(t, Î¸á´®[k, s, h, :], T = T))) for k = 1:K, t = 1:T, s = 1:D, h = 1:size_memory]
    B[:, :, :, :] = Bernoulli.(p)
end

function fit_mle_one_B(Î¸á´®, model_B, Î³â‚›; warm_start = true)
    T, rain_cat = size(Î³â‚›)
    Î¸_jump = model_B[:Î¸_jump]
    warm_start && set_start_value.(Î¸_jump, Î¸á´®[:])
    Ï€â‚› = model_B[:Ï€â‚›]

    for t = 1:T, y = 1:rain_cat
        set_value(Ï€â‚›[t, y], Î³â‚›[t, y])
    end
    optimize!(model_B)
    return value.(Î¸_jump)
end

# JuMP model use to increase R(Î¸,Î¸^i) for the Q(t) matrix
function model_for_A(s_Î¾::AbstractArray, d::Int; silence = true)
    T, K = size(s_Î¾)
    model = Model(Ipopt.Optimizer)
    set_optimizer_attribute(model, "max_iter", 200)
    silence && set_silent(model)
    f = 2Ï€ / T
    cos_nj = [cos(f * j * t) for t = 1:T, j = 1:d]
    sin_nj = [sin(f * j * t) for t = 1:T, j = 1:d]

    trig = [[1; interleave2(cos_nj[t, :], sin_nj[t, :])] for t = 1:T]

    @variable(model, pklj_jump[l = 1:(K-1), j = 1:(2d+1)], start = 0.01)
    # Polynomial P_kl
    @NLexpression(model, Pkl[t = 1:T, l = 1:K-1], sum(trig[t][j] * pklj_jump[l, j] for j = 1:length(trig[t])))

    @NLparameter(model, s_Ï€kl[t = 1:T, l = 1:K-1] == s_Î¾[t, l])
    #TODO? is it useful to define the extra parameter for the sum?
    @NLparameter(model, s_Ï€k[t = 1:T] == sum(s_Î¾[t, l] for l = 1:K))

    @NLobjective(
        model,
        Max,
        sum(sum(s_Ï€kl[t, l] * Pkl[t, l] for l = 1:K-1) - s_Ï€k[t] * log1p(sum(exp(Pkl[t, l]) for l = 1:K-1)) for t = 1:T)
    )
    # To add NL parameters to the model for later use https://discourse.julialang.org/t/jump-updating-nlparameter-of-a-model-in-a-loop/35081/3
    model[:s_Ï€kl] = s_Ï€kl
    model[:s_Ï€k] = s_Ï€k
    return model
end

function update_A!(
    A::AbstractArray{<:AbstractFloat,3},
    Î¸á´¬::AbstractArray{<:AbstractFloat,3},
    Î¾::AbstractArray,
    s_Î¾::AbstractArray,
    Î±::AbstractMatrix,
    Î²::AbstractMatrix,
    LL::AbstractMatrix,
    n2t::AbstractArray{Int},
    n_in_t,
    model_A::Model;
    warm_start = true
) 
    @argcheck size(Î±, 1) == size(Î², 1) == size(LL, 1) == size(Î¾, 1)
    @argcheck size(Î±, 2) ==
              size(Î², 2) ==
              size(LL, 2) ==
              size(A, 1) ==
              size(A, 2) ==
              size(Î¾, 2) ==
              size(Î¾, 3)

    N, K = size(LL)
    T = size(A, 3)
    @inbounds for n in OneTo(N - 1)
        t = n2t[n] # periodic t
        m = vec_maximum(view(LL, n + 1, :))
        c = 0

        for i in OneTo(K), j in OneTo(K)
            Î¾[n, i, j] = Î±[n, i] * A[i, j, t] * exp(LL[n+1, j] - m) * Î²[n+1, j]
            c += Î¾[n, i, j]
        end

        for i in OneTo(K), j in OneTo(K)
            Î¾[n, i, j] /= c
        end
    end
    ## 
    # Î¾ are the filtering probablies
    s_Î¾!(s_Î¾, Î¾, n_in_t)
    Î¸_res = pmap(k -> fit_mle_one_A(Î¸á´¬[k, :, :], model_A, s_Î¾[:, k, :]; warm_start = warm_start), 1:K)

    for k = 1:K
        Î¸á´¬[k, :, :] = Î¸_res[k][:, :]
    end

    for k = 1:K, l = 1:K-1, t = 1:T
        A[k, l, t] = exp(polynomial_trigo(t, Î¸á´¬[k, l, :], T=T))
    end
    for k = 1:K, t = 1:T
        A[k, K, t] = 1  # last colum is 1/normalization (one could do otherwise)
    end
    normalization_polynomial = [1 + sum(A[k, l, t] for l = 1:K-1) for k = 1:K, t = 1:T]
    for k = 1:K, l = 1:K, t = 1:T
        A[k, l, t] /= normalization_polynomial[k, t]
    end
end

function fit_mle_one_A(Î¸á´¬, model, s_Î¾; warm_start = true)
    T, K = size(s_Î¾)
    pklj_jump = model[:pklj_jump]
    s_Ï€k = model[:s_Ï€k]
    s_Ï€kl = model[:s_Ï€kl]
    ## Update the smoothing parameters in the JuMP model
    for t = 1:T
        set_value(s_Ï€k[t], sum(s_Î¾[t, l] for l = 1:K))
        for l = 1:K-1
            set_value(s_Ï€kl[t, l], s_Î¾[t, l])
        end
    end
    warm_start && set_start_value.(pklj_jump, Î¸á´¬[:, :])
    # Optimize the updated model
    optimize!(model)
    # Obtained the new parameters
    return value.(pklj_jump)
end

function fit_mle!(
    hmm::HierarchicalPeriodicHMM,
    Î¸á´¬::AbstractArray{<:AbstractFloat,3},
    Î¸á´®::AbstractArray{<:AbstractFloat,4},
    ð˜::AbstractArray{<:Bool},
    ð˜_past::AbstractArray{<:Bool}
    ;
    n2t=n_to_t(size(ð˜, 1), size(hmm, 3))::AbstractVector{<:Integer},
    display=:none,
    maxiter=100,
    tol=1e-3,
    robust=false,
    silence=true,
    warm_start=true
)
    @argcheck display in [:none, :iter, :final]
    @argcheck maxiter >= 0

    N, K, T, size_memory, D = size(ð˜, 1), size(hmm, 1), size(hmm, 3), size(hmm, 4), size(hmm, 2)

    deg_Î¸á´¬ = (size(Î¸á´¬, 3) - 1) Ã· 2
    deg_Î¸á´® = (size(Î¸á´®, 4) - 1) Ã· 2
    rain_cat = 2 # dry or wet
    @argcheck T == size(hmm.B, 2)
    history = EMHistory(false, 0, [])

    all_Î¸á´¬áµ¢ = [copy(Î¸á´¬)]
    all_Î¸á´®áµ¢ = [copy(Î¸á´®)]
    # Allocate memory for in-place updates
    c = zeros(N)
    Î± = zeros(N, K)
    Î² = zeros(N, K)
    Î³ = zeros(N, K) # regular smoothing proba
    Î³â‚› = zeros(K, D, size_memory, T, rain_cat) # summed smoothing proba
    Î¾ = zeros(N, K, K)
    s_Î¾ = zeros(T, K, K)
    LL = zeros(N, K)

    # assign category for observation depending in the ð˜_past ð˜
    memory = Int(log2(size_memory))
    lag_cat = conditional_to(ð˜, ð˜_past)

    n_in_t = [findall(n2t .== t) for t = 1:T]
    n_occurence_history = [findall(.&(ð˜[:, j] .== y, lag_cat[:, j] .== h)) for j = 1:D, h = 1:size_memory, y = 0:1] # dry or wet
    n_all = [n_per_category(tup..., n_in_t, n_occurence_history) for tup in Iterators.product(1:D, 1:size_memory, 1:T, 1:rain_cat)]

    model_A = model_for_A(s_Î¾[:, 1, :], deg_Î¸á´¬, silence=silence) # JuMP Model for transition matrix
    model_B = model_for_B(Î³â‚›[1, 1, 1, :, :], deg_Î¸á´®, silence=silence) # JuMP Model for Emmission distribution

    loglikelihoods!(LL, hmm, ð˜, lag_cat; n2t=n2t)
    robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))

    forwardlog!(Î±, c, hmm.a, hmm.A, LL; n2t=n2t)
    backwardlog!(Î², c, hmm.a, hmm.A, LL; n2t=n2t)
    posteriors!(Î³, Î±, Î²)

    logtot = sum(c)
    (display == :iter) && println("Iteration 0: logtot = $logtot")

    for it = 1:maxiter
        update_a!(hmm.a, Î±, Î²)
        update_A!(hmm.A, Î¸á´¬, Î¾, s_Î¾, Î±, Î², LL, n2t, n_in_t, model_A; warm_start=warm_start)
        update_B!(hmm.B, Î¸á´®, Î³, Î³â‚›, ð˜, n_all, model_B; warm_start=warm_start)
        # Ensure the "connected-ness" of the states,
        # this prevents case where there is no transitions
        # between two extremely likely ð˜.
        robust && (hmm.A .+= eps())
    
        @check isprobvec(hmm.a)
        @check all(t -> istransmat(hmm.A[:, :, t]), OneTo(T))
    
        push!(all_Î¸á´¬áµ¢, copy(Î¸á´¬))
        push!(all_Î¸á´®áµ¢, copy(Î¸á´®))
    
        # loglikelihoods!(LL, hmm, ð˜, n2t)
        loglikelihoods!(LL, hmm, ð˜, lag_cat; n2t=n2t)
    
        robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))
    
        forwardlog!(Î±, c, hmm.a, hmm.A, LL; n2t=n2t)
        backwardlog!(Î², c, hmm.a, hmm.A, LL; n2t=n2t)
        posteriors!(Î³, Î±, Î²)
    
        logtotp = sum(c)
        (display == :iter) && println(now(), " Iteration $it: logtot = $logtotp")
        flush(stdout)
    
        push!(history.logtots, logtotp)
        history.iterations += 1
    
        if abs(logtotp - logtot) < tol
            (display in [:iter, :final]) &&
                println("EM converged in $it iterations, logtot = $logtotp")
            history.converged = true
            break
        end
    
        logtot = logtotp
    end

    if !history.converged
        if display in [:iter, :final]
            println("EM has not converged after $(history.iterations) iterations, logtot = $logtot")
        end
    end

    history, all_Î¸á´¬áµ¢, all_Î¸á´®áµ¢
end

function fit_mle(hmm::HierarchicalPeriodicHMM,
    Î¸á´¬::AbstractArray{<:AbstractFloat,3},
    Î¸á´®::AbstractArray{<:AbstractFloat,4},
    ð˜::AbstractArray{<:Bool},
    ð˜_past::AbstractArray{<:Bool}; 
    all_iters=false, kwargs...)

    hmm = copy(hmm)
    Î¸á´¬ = copy(Î¸á´¬)
    Î¸á´® = copy(Î¸á´®)
    history, all_Î¸á´¬áµ¢, all_Î¸á´®áµ¢ = fit_mle!(hmm, ð˜, n2t, Î¸á´¬, Î¸á´®; kwargs...)
    if all_iters == true
        return hmm, Î¸á´¬, Î¸á´®, history, all_Î¸á´¬áµ¢, all_Î¸á´®áµ¢
    else
        return hmm, Î¸á´¬, Î¸á´®, history
    end
end

# TODO add possibility of memory different at each site
# function fit_mle!(
#     hmm::HierarchicalPeriodicHMM,
#     ð˜::AbstractArray,
#     n2t::AbstractArray{Int},
#     Î¸á´¬::AbstractArray{TQ,3} where {TQ},
#     Î¸á´®::AbstractArray{TY,4} where {TY},
#     size_memories::AbstractVector # Vector of all local memory when there are not indentical
#     ;
#     display = :none,
#     maxiter = 100,
#     tol = 1e-3,
#     robust = false,
#     silence = true,
#     warm_start = true,
#     ð˜_past = [0 1 0 1 1 0 1 0 0 0
#         1 1 0 1 1 1 1 1 1 1
#         1 1 0 1 1 1 0 1 1 1
#         1 1 0 1 1 0 0 0 1 0
#         1 1 0 1 1 0 0 1 0 1]
# )
#     @argcheck display in [:none, :iter, :final]
#     @argcheck maxiter >= 0

#     N, K, T, D = size(ð˜, 1), size(hmm, 1), size(hmm, 3), size(hmm, 2)
#     @argcheck length(size_memories) == D
#     max_size_memory = maximum(size_memories)

#     deg_Î¸á´¬ = (size(Î¸á´¬, 3) - 1) Ã· 2
#     deg_Î¸á´® = (size(Î¸á´®, 4) - 1) Ã· 2
#     rain_cat = 2
#     @argcheck T == size(hmm.B, 2)
#     history = EMHistory(false, 0, [])

#     all_Î¸á´¬áµ¢ = [copy(Î¸á´¬)]
#     all_Î¸á´®áµ¢ = [copy(Î¸á´®)]
#     # Allocate memory for in-place updates
#     c = zeros(N)
#     Î± = zeros(N, K)
#     Î² = zeros(N, K)
#     Î³ = zeros(N, K) # regular smoothing proba
#     Î³â‚› = zeros(K, D, max_size_memory, T, rain_cat) # summed smoothing proba
#     Î¾ = zeros(N, K, K)
#     s_Î¾ = zeros(T, K, K)
#     LL = zeros(N, K)

#     # assign category for observation depending in the ð˜_past ð˜
#     memories = Int.(log.(size_memories) / log(2))
#     lag_cat = conditional_to(ð˜, ð˜_past)

#     n_in_t = [findall(n2t .== t) for t = 1:T]
#     n_occurence_history = [findall(.&(ð˜[:, j] .== y, lag_cat[:, j] .== h)) for j = 1:D, h = 1:max_size_memory, y = 0:1]
#     n_all = [n_per_category(tup..., n_in_t, n_occurence_history) for tup in Iterators.product(1:D, 1:max_size_memory, 1:T, 1:rain_cat)]

#     model_A = model_for_A(s_Î¾[:, 1, :], deg_Î¸á´¬, silence = silence) # JuMP Model for transition matrix
#     model_B = model_for_B(Î³â‚›[1, 1, 1, :, :], deg_Î¸á´®, silence = silence) # JuMP Model for Emmission distribution

#     loglikelihoods!(LL, hmm, ð˜, n2t, lag_cat)
#     robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))

#     forwardlog!(Î±, c, hmm.a, hmm.A, LL, n2t)
#     backwardlog!(Î², c, hmm.a, hmm.A, LL, n2t)
#     posteriors!(Î³, Î±, Î²)

#     logtot = sum(c)
#     (display == :iter) && println("Iteration 0: logtot = $logtot")

#     for it = 1:maxiter
#         update_a!(hmm.a, Î±, Î²)
#         update_A!(hmm.A, Î¸á´¬, Î¾, s_Î¾, Î±, Î², LL, n2t, n_in_t, model_A; warm_start = warm_start)
#         update_B!(hmm.B, Î¸á´®, Î³, Î³â‚›, ð˜, n_all, model_B; warm_start = warm_start)
#         # Ensure the "connected-ness" of the states,
#         # this prevents case where there is no transitions
#         # between two extremely likely ð˜.
#         robust && (hmm.A .+= eps())

#         @check isprobvec(hmm.a)
#         @check istransmats(hmm.A)

#         push!(all_Î¸á´¬áµ¢, copy(Î¸á´¬))
#         push!(all_Î¸á´®áµ¢, copy(Î¸á´®))

#         # loglikelihoods!(LL, hmm, ð˜, n2t)
#         loglikelihoods!(LL, hmm, ð˜, n2t, lag_cat)

#         robust && replace!(LL, -Inf => nextfloat(-Inf), Inf => log(prevfloat(Inf)))

#         forwardlog!(Î±, c, hmm.a, hmm.A, LL, n2t)
#         backwardlog!(Î², c, hmm.a, hmm.A, LL, n2t)
#         posteriors!(Î³, Î±, Î²)

#         logtotp = sum(c)
#         (display == :iter) && println(now(), " Iteration $it: logtot = $logtotp")
#         flush(stdout)

#         push!(history.logtots, logtotp)
#         history.iterations += 1

#         if abs(logtotp - logtot) < tol
#             (display in [:iter, :final]) &&
#                 println("EM converged in $it iterations, logtot = $logtotp")
#             history.converged = true
#             break
#         end

#         logtot = logtotp
#     end

#     if !history.converged
#         if display in [:iter, :final]
#             println("EM has not converged after $(history.iterations) iterations, logtot = $logtot")
#         end
#     end

#     history, all_Î¸á´¬áµ¢, all_Î¸á´®áµ¢
# end